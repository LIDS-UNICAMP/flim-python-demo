{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from pyflim import flim, arch, data, metrics, util\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_folder = \"data/orig/\"\n",
    "marker_folder = \"data/markers/\"\n",
    "label_folder = \"data/label/\"\n",
    "orig_ext = \".png\"\n",
    "label_ext = \".png\"\n",
    "marker_ext = \"-seeds.txt\"\n",
    "file_list = \"./train.txt\"\n",
    "\n",
    "train_by_batch=True\n",
    "if(not train_by_batch):\n",
    "    dataset = data.FLIMData(orig_folder, images_list=file_list, marker_folder=marker_folder, orig_ext=orig_ext, marker_ext=marker_ext,\n",
    "                                                 transform=data.transforms.Compose([data.ToTensor()]))\n",
    "else:\n",
    "    dataset_ = data.FLIMData(orig_folder, images_list=file_list, label_folder=None, label_ext=label_ext, marker_folder=marker_folder, orig_ext=orig_ext, marker_ext=marker_ext,\n",
    "                                                 transform=data.transforms.Compose([\n",
    "                                                     data.Rescale(256),\n",
    "                                                     data.ToTensor()]))\n",
    "    sampler = torch.utils.data.sampler.BatchSampler(torch.utils.data.sampler.RandomSampler(dataset_),\n",
    "                                                    batch_size=5,drop_last=False)\n",
    "\n",
    "    dataset = DataLoader(dataset_, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = arch.FLIMArchitecture(\"arch.json\")\n",
    "model = flim.FLIMModel(architecture, adaptation_function=\"robust_weights\", device=\"cpu\", filter_by_size=False, track_gpu_stats=True)\n",
    "start = time.time()\n",
    "model.fit(dataset)\n",
    "stop = time.time()\n",
    "print('Network trained in:', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.run(dataset, \"out/\")\n",
    "stop = time.time()\n",
    "print('Forward pass in:', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model parameters: \", util.get_model_n_params(model), \"(M)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = \"./val.txt\"\n",
    "\n",
    "train_by_batch=False\n",
    "if(not train_by_batch):\n",
    "    dataset = data.FLIMData(orig_folder, images_list=file_list, orig_ext=orig_ext,\n",
    "                                                 transform=data.transforms.Compose([data.ToTensor()]))\n",
    "else:\n",
    "    dataset_ = data.FLIMData(orig_folder, images_list=file_list, orig_ext=orig_ext,\n",
    "                                                 transform=data.transforms.Compose([\n",
    "                                                     data.Rescale(256),\n",
    "                                                     data.ToTensor()]))\n",
    "    sampler = torch.utils.data.sampler.BatchSampler(torch.utils.data.SequentialSampler(dataset_),\n",
    "                                                    batch_size=5,drop_last=False)\n",
    "\n",
    "    dataset = DataLoader(dataset_, batch_sampler=sampler)\n",
    "\n",
    "start = time.time()\n",
    "model.run(dataset, \"out/\")\n",
    "stop = time.time()\n",
    "print('Forward pass in:', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflim import flim, arch, data, metrics, util\n",
    "file_list = \"./val.txt\"\n",
    "label_folder = \"data/label/\"\n",
    "results_folder = \"out/\"\n",
    "\n",
    "metricas = metrics.FLIMMetrics()\n",
    "metricas.evaluate_saliency_results(results_folder, label_folder, file_list=util.readFileList(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas.print_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
